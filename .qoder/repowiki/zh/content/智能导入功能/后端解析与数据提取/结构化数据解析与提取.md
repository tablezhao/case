# 结构化数据解析与提取

<cite>
**本文档引用文件**   
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts)
- [api.ts](file://src/db/api.ts)
- [compliance_rules.ts](file://src/db/compliance_rules.ts)
- [extractViolationKeywords.test.ts](file://src/db/extractViolationKeywords.test.ts)
- [ParseTestPage.tsx](file://src/pages/admin/ParseTestPage.tsx)
- [00022_enhance_high_frequency_issues_with_semantic_split.sql](file://supabase/migrations/00022_enhance_high_frequency_issues_with_semantic_split.sql)
</cite>

## 目录
1. [引言](#引言)
2. [核心提取函数实现机制](#核心提取函数实现机制)
3. [正则表达式与关键词识别策略](#正则表达式与关键词识别策略)
4. [业务规则与数据处理逻辑](#业务规则与数据处理逻辑)
5. [置信度计算与完整性评估](#置信度计算与完整性评估)
6. [实际文本匹配示例](#实际文本匹配示例)
7. [总结](#总结)

## 引言
本文档详细阐述了云函数中结构化数据提取的完整逻辑，重点分析了`extractDate`、`extractAppName`、`extractDeveloper`、`extractDepartment`、`extractPlatform`、`extractViolationSummary`和`extractViolationDetail`七个核心提取函数的实现机制。文档深入解析了正则表达式模式匹配策略、关键词识别算法、文本片段提取逻辑，并详细说明了日期格式标准化、监管部门名称归一化、违规摘要长度限制（150字符）和详细内容截取（前5个相关句子，1000字符限制）等关键业务规则。同时，提供了实际的文本匹配示例，并解释了基于7个字段提取完整性的置信度计算方法。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L1-L129)

## 核心提取函数实现机制

### 日期提取 (extractDate)
该函数通过一系列正则表达式模式匹配文本中的日期信息。它支持多种日期格式，包括`YYYY年MM月DD日`、`YYYY-MM-DD`以及带有“发布时间”或“通报时间”前缀的日期。一旦匹配成功，函数会将提取到的年、月、日部分进行格式化，统一输出为`YYYY-MM-DD`的标准化格式。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L214-L233)

### 应用名称提取 (extractAppName)
此函数利用多个正则表达式模式来识别应用名称。模式包括“应用名称：《XXX》”、“App名称：XXX”、“软件名称：XXX”等标准字段，以及从文本中直接捕获应用名的模式（如`《XXX》存在...问题`）。它能够处理带书名号或引号的应用名，并返回匹配到的第一个有效结果。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L235-L249)

### 开发者信息提取 (extractDeveloper)
开发者信息的提取通过匹配“开发者：XXX”、“运营者：XXX”、“开发单位：XXX”等关键词来实现。此外，它还包含一个更通用的模式，用于匹配文本中出现的公司、企业、工作室或团队等实体名称，从而捕获开发者信息。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L252-L267)

### 监管部门提取 (extractDepartment)
该函数采用关键词匹配策略，预定义了一个包含国家级和省级监管部门的列表（如“工业和信息化部”、“国家互联网信息办公室”、“工信部”等）。它首先在文本中搜索这些关键词，如果匹配到简称（如“工信部”），则会将其归一化为全称（“工业和信息化部”）。对于省级部门，它还支持通过正则表达式匹配“XX省/市通信管理局”等形式。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L269-L296)

### 应用平台提取 (extractPlatform)
平台提取逻辑基于一个预定义的主流应用商店和平台列表（如“应用宝”、“华为应用市场”、“App Store”等）。函数通过简单的字符串包含检查（`text.includes(platform)`）来判断文本中是否提到了某个平台，并返回第一个匹配到的平台名称。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L298-L319)

### 违规摘要提取 (extractViolationSummary)
违规摘要的提取结合了正则表达式和长度限制。它通过匹配“违规问题：XXX”、“主要问题：XXX”等字段来捕获摘要内容。为了确保摘要的简洁性，函数会检查提取到的文本长度，如果超过150字符，则将其截断并添加省略号（`...`）。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L321-L343)

### 违规详情提取 (extractViolationDetail)
该函数的逻辑更为复杂，旨在提取与违规相关的详细文本片段。它首先将输入文本按句号、感叹号、问号或换行符分割成句子。然后，它会筛选出包含特定关键词（如“违规”、“问题”、“收集”、“权限”、“个人信息”等）且长度在20到500字符之间的句子。最终，它取前5个符合条件的句子，连接成一个段落，并确保总长度不超过1000字符，超出部分同样以省略号结尾。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L345-L367)

## 正则表达式与关键词识别策略

### 正则表达式模式设计
提取函数广泛使用正则表达式进行模式匹配。其设计原则是：
1.  **精确性**：使用捕获组 `( )` 精确定位需要提取的文本部分。
2.  **灵活性**：允许匹配多种变体，例如使用 `[：:]` 匹配中文或英文冒号，使用 `\s*` 匹配任意数量的空白字符。
3.  **长度控制**：在捕获组中使用 `{2,30}` 等量词来限制匹配文本的最小和最大长度，避免匹配到过短或过长的无关内容。

### 关键词智能识别与补全
系统不仅进行简单的关键词匹配，还实现了智能补全和标准化。`extractViolationKeywords` 函数是这一策略的核心，其工作流程如下：
1.  **分号分割**：首先将违规内容按中文分号 `；` 分割成多个独立的描述片段。
2.  **正则匹配**：对每个片段应用一组预定义的正则表达式模式，这些模式覆盖了个人信息收集、权限滥用、隐私政策缺失等八大类违规行为。
3.  **智能补全**：对于匹配到的关键词（如“超范围收集”），通过 `normalizeKeyword` 函数将其映射为更完整、更标准的法律表述（如“超范围收集个人信息”）。这依赖于一个 `COMPLIANCE_MAP` 映射表。
4.  **兜底处理**：对于未被正则匹配但长度适中的片段，也会尝试进行标准化处理并保留，以确保信息不丢失。

```mermaid
flowchart TD
A[原始违规内容] --> B[按分号"；"拆分]
B --> C{遍历每个片段}
C --> D[应用正则表达式模式匹配]
D --> E{是否匹配?}
E --> |是| F[提取关键词]
F --> G[通过normalizeKeyword补全]
G --> H[去重后加入结果集]
E --> |否| I{长度<=50?}
I --> |是| J[尝试标准化后加入]
I --> |否| K[忽略]
C --> L{所有片段处理完毕?}
L --> |否| C
L --> |是| M[返回标准化关键词列表]
```

**Diagram sources**
- [api.ts](file://src/db/api.ts#L2162-L2257)
- [compliance_rules.ts](file://src/db/compliance_rules.ts#L75-L95)
- [00022_enhance_high_frequency_issues_with_semantic_split.sql](file://supabase/migrations/00022_enhance_high_frequency_issues_with_semantic_split.sql#L74-L87)

## 业务规则与数据处理逻辑

### 日期格式标准化
所有提取到的日期，无论其原始格式如何（如`2024年1月1日`或`2024-01-01`），都会被统一转换为 `YYYY-MM-DD` 的ISO标准格式，确保数据的一致性和可排序性。

### 监管部门名称归一化
为保证数据的统一性，系统对监管部门名称进行归一化处理。例如，当文本中出现“工信部”或“网信办”时，系统会自动将其转换为全称“工业和信息化部”和“国家互联网信息办公室”。

### 违规摘要长度限制
为确保摘要的简洁性和在UI中的良好展示，提取到的违规摘要内容被严格限制在150字符以内。如果原始内容超过此长度，系统会自动截断并在末尾添加省略号（`...`）。

### 详细内容截取规则
违规详情的提取遵循以下规则：
1.  **句子筛选**：只保留包含特定关键词且长度在20-500字符之间的句子。
2.  **数量限制**：最多选取前5个符合条件的句子。
3.  **总长度限制**：所有选中的句子连接后，总长度不得超过1000字符，超出部分以省略号结尾。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L214-L367)

## 置信度计算与完整性评估
系统的置信度计算是一种基于字段完整性的简单而有效的评估方法。其计算逻辑如下：
1.  **字段列表**：定义了7个核心提取字段：`report_date`, `app_name`, `developer`, `department`, `platform`, `violation_summary`, `violation_detail`。
2.  **完整性计数**：统计这7个字段中成功提取出非空值的字段数量。
3.  **置信度计算**：将成功提取的字段数除以7，得到一个0到1之间的置信度分数。例如，如果成功提取了5个字段，则置信度为 `5/7 ≈ 0.71`。

此分数反映了输入文本的结构化程度和信息完整性，为后续的数据处理和人工审核提供了重要参考。

**Section sources**
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L96-L101)

## 实际文本匹配示例

### 示例1：标准通报文本
**输入文本**：
```
根据《关于侵害用户权益行为的APP通报》（2024年第1期），工业和信息化部通报了存在违规收集个人信息问题的App。应用名称：《示例App》；开发者：某某科技有限公司；应用平台：应用宝。主要问题：违规收集用户个人信息，包括通讯录、位置信息等，未经用户明确同意。
```

**提取结果**：
-   **日期**：`2024-01-01` (从“2024年第1期”推断)
-   **应用名称**：`示例App`
-   **开发者**：`某某科技有限公司`
-   **监管部门**：`工业和信息化部`
-   **平台**：`应用宝`
-   **违规摘要**：`违规收集用户个人信息，包括通讯录、位置信息等，未经用户明确同意` (长度约45字符，未超限)
-   **违规详情**：`违规收集用户个人信息，包括通讯录、位置信息等，未经用户明确同意。` (匹配到1个相关句子)

### 示例2：复合违规描述
**输入文本**：
```
某App存在超范围收集个人信息；APP强制、频繁、过度索取权限；欺骗误导用户下载等问题。
```

**提取结果**：
-   **违规摘要**：`超范围收集个人信息` (匹配到第一个符合长度的模式)
-   **违规详情**：`某App存在超范围收集个人信息；APP强制、频繁、过度索取权限；欺骗误导用户下载等问题。` (整句包含多个关键词，被完整提取)
-   **关键词提取**：`["超范围收集个人信息", "强制用户授权非必要权限", "频繁申请非必要权限", "过度索取系统权限", "欺骗误导用户提供个人信息"]` (通过`extractViolationKeywords`函数拆分并补全)

**Section sources**
- [ParseTestPage.tsx](file://src/pages/admin/ParseTestPage.tsx#L26-L32)
- [index.ts](file://supabase/functions/parse-multimodal-case/index.ts#L321-L367)

## 总结
本文档全面解析了云函数中结构化数据提取的完整技术栈。系统通过精心设计的正则表达式和关键词匹配算法，实现了对非结构化文本的高效解析。其核心优势在于结合了模式匹配的精确性与智能补全的灵活性，并通过严格的业务规则（如长度限制、名称归一化）确保了输出数据的质量和一致性。基于字段完整性的置信度计算模型，为评估提取结果的可靠性提供了量化依据。整个流程从原始文本输入到结构化数据输出，形成了一个完整、可靠且可维护的数据处理闭环。